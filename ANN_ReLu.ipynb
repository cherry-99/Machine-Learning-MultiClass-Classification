{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import Normalizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"working_csv.csv\")\n",
    "cols = df.columns\n",
    "col_list = [\"P. Habitable Class\",\"P. Teq Max (K)\",\"S. Mag from Planet\",\"P. SFlux Mean (EU)\",\"S. Teff (K)\",\"P. Mag\",\"P. HZD\",\"P. ESI\",\"P. SPH\",\"P. HZC\",\"P. Gravity (EU)\",\"S. Size from Planet (deg)\",\"S. [Fe/H]\",\"S. DEC (deg)\",\"P. SFlux Min (EU)\",\"S. Hab Zone Max (AU)\",\"P. HZI\",\"P. Eccentricity\",\"P. Appar Size (deg)\"]\n",
    "for words in cols:\n",
    "    if words not in col_list:\n",
    "        df.drop(columns = [words] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 19) (43,)\n",
      "(11, 19) (11,)\n"
     ]
    }
   ],
   "source": [
    "y = df[\"P. Habitable Class\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, y, test_size=0.2)\n",
    "\n",
    "print (X_train.shape, Y_train.shape)\n",
    "print (X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.39000000e+00  1.46133200e+00  1.46133200e+00  2.80100000e+02\n",
      "  -1.83200000e+01  2.66000000e+00  0.00000000e+00  3.49700000e+03\n",
      "  -6.02714085e-02 -9.61240000e+00 -2.71000000e+01  1.75880000e+00\n",
      "   3.11000000e-01 -9.90000000e-01 -1.60000000e-01  5.00000000e-01\n",
      "   6.00000000e-02  8.20000000e-01]\n",
      " [ 2.07000000e+00  9.02172800e-01  9.02172900e-01  2.48300000e+02\n",
      "  -1.83200000e+01  3.38000000e+00  0.00000000e+00  4.88600000e+03\n",
      "  -6.02714085e-02  4.92125000e+01 -2.66000000e+01  7.07900000e-01\n",
      "   1.01200000e+00 -5.30000000e-01 -1.40000000e-01  5.50000000e-01\n",
      "   8.50000000e-01  8.00000000e-01]\n",
      " [ 2.24000000e+00  7.51445800e-01  1.43441000e+00  3.38000000e+02\n",
      "  -1.89900000e+01  3.54000000e+00  3.40000000e-01  4.13400000e+03\n",
      "  -3.00000000e-01  4.14522000e+01 -2.72000000e+01  1.28570000e+00\n",
      "   5.71000000e-01 -8.90000000e-01 -1.40000000e-01  4.80000000e-01\n",
      "   1.60000000e-01  7.50000000e-01]\n",
      " [ 1.52000000e+00  1.21709400e+02  1.21709400e+02  8.46200000e+02\n",
      "  -2.32600000e+01  2.81000000e+00  0.00000000e+00  6.09200000e+03\n",
      "  -6.02714085e-02  4.25280000e+01 -3.20000000e+01  5.29070000e+00\n",
      "   2.50700000e+00 -2.31000000e+00 -1.60000000e-01  2.90000000e-01\n",
      "   0.00000000e+00  2.90000000e-01]\n",
      " [ 1.39000000e+00  2.90249000e-01  3.02029500e-01  1.90800000e+02\n",
      "  -1.65900000e+01  2.65000000e+00  2.00000000e-02  3.35000000e+03\n",
      "  -5.50000000e-01 -3.49897000e+01 -2.54000000e+01  8.71400000e-01\n",
      "   2.51000000e-01  5.10000000e-01 -1.60000000e-01  6.30000000e-01\n",
      "   0.00000000e+00  6.00000000e-01]\n",
      " [ 2.17000000e+00  5.51556900e-01  6.63001900e-01  2.41300000e+02\n",
      "  -1.80500000e+01  3.48000000e+00  9.00000000e-02  3.84000000e+03\n",
      "  -6.02714085e-02 -5.33736000e+01 -2.63000000e+01  9.88100000e-01\n",
      "   2.12000000e-01 -3.40000000e-01 -1.40000000e-01  5.30000000e-01\n",
      "   8.00000000e-02  7.30000000e-01]\n",
      " [ 6.80000000e-01  4.92721300e-01  4.92721300e-01  2.13400000e+02\n",
      "  -1.92200000e+01  6.92000000e+00  0.00000000e+00  5.56000000e+03\n",
      "  -1.36000000e-01  4.05209000e+01 -2.60000000e+01  4.04000000e-01\n",
      "   1.56900000e+00  2.80000000e-01  2.88000000e+00  2.60000000e-01\n",
      "   0.00000000e+00  5.30000000e-01]\n",
      " [ 2.26000000e+00  1.38738000e+00  1.38738000e+00  2.76500000e+02\n",
      "  -1.89000000e+01  3.56000000e+00  0.00000000e+00  5.71000000e+03\n",
      "  -6.02714085e-02  4.85244000e+01 -2.71000000e+01  6.42700000e-01\n",
      "   1.65000000e+00 -8.10000000e-01 -1.40000000e-01  4.90000000e-01\n",
      "   2.00000000e-02  7.60000000e-01]\n",
      " [ 3.60000000e+00  7.18864100e-01  8.91031300e-01  2.62000000e+02\n",
      "  -1.89000000e+01  4.43000000e+00  1.10000000e-01  4.72300000e+03\n",
      "  -1.00000000e-02  4.99686000e+01 -2.66000000e+01  7.55200000e-01\n",
      "   9.03000000e-01 -5.30000000e-01 -1.20000000e-01  3.40000000e-01\n",
      "   9.80000000e-01  7.10000000e-01]\n",
      " [ 2.01000000e+00  2.68782900e-01  3.39578800e-01  2.06900000e+02\n",
      "  -1.72200000e+01  3.33000000e+00  1.20000000e-01  3.57200000e+03\n",
      "  -1.20000000e-01  4.94373000e+01 -2.56000000e+01  8.15500000e-01\n",
      "   3.47000000e-01  4.00000000e-01 -1.40000000e-01  5.10000000e-01\n",
      "   0.00000000e+00  6.00000000e-01]\n",
      " [ 4.61000000e+00  3.31142500e+01  5.34272200e+01  7.89000000e+02\n",
      "  -2.68100000e+01  2.13000000e+01  2.50000000e-01  4.55300000e+03\n",
      "  -9.00000000e-02  2.34622000e+01 -3.11000000e+01  6.37870000e+00\n",
      "   1.69790000e+01 -2.13000000e+00  7.27000000e+00  1.10000000e-01\n",
      "   0.00000000e+00  1.20000000e-01]\n",
      " [ 3.81000000e+00  1.79143900e+02  1.79144000e+02  9.32100000e+02\n",
      "  -2.47300000e+01  4.53000000e+00  0.00000000e+00  5.83900000e+03\n",
      "  -6.02714085e-02  5.16958000e+01 -3.24000000e+01  6.98890000e+00\n",
      "   1.86800000e+00 -2.33000000e+00 -1.20000000e-01  3.00000000e-01\n",
      "   0.00000000e+00  2.40000000e-01]\n",
      " [ 1.66000000e+00  4.55976600e+02  4.98421100e+02  1.23150000e+03\n",
      "  -2.91600000e+01  2.08200000e+01  4.00000000e-02  5.34000000e+03\n",
      "   4.50000000e-01  5.02258000e+01 -3.35000000e+01  1.39710000e+01\n",
      "   1.51300000e+00 -2.36000000e+00  7.37000000e+00  1.10000000e-01\n",
      "   0.00000000e+00  8.00000000e-02]\n",
      " [ 2.14000000e+00  8.98436000e-01  8.98436100e-01  2.48000000e+02\n",
      "  -1.83600000e+01  3.45000000e+00  0.00000000e+00  4.35100000e+03\n",
      "  -2.60000000e-01  4.78390000e+01 -2.66000000e+01  8.90800000e-01\n",
      "   6.46000000e-01 -5.80000000e-01 -1.40000000e-01  5.20000000e-01\n",
      "   8.50000000e-01  7.90000000e-01]\n",
      " [ 7.60000000e-01  6.54407900e-01  6.54408000e-01  2.29100000e+02\n",
      "  -1.65200000e+01  1.74000000e+00  0.00000000e+00  2.55000000e+03\n",
      "   4.00000000e-02 -5.04140000e+00 -2.63000000e+01  2.21350000e+00\n",
      "   5.10000000e-02 -4.20000000e-01 -1.50000000e-01  5.60000000e-01\n",
      "   0.00000000e+00  8.50000000e-01]\n",
      " [ 2.15000000e+00  1.86649800e+00  2.40345200e+00  3.39400000e+02\n",
      "  -2.29600000e+01  1.73400000e+01  1.30000000e-01  5.71000000e+03\n",
      "   6.00000000e-02 -2.60267000e+01 -2.77000000e+01  8.49600000e-01\n",
      "   1.56500000e+00 -1.20000000e+00  5.68000000e+00  1.30000000e-01\n",
      "   0.00000000e+00  4.30000000e-01]\n",
      " [ 2.15000000e+00  3.89528200e-01  6.77168700e-01  2.71300000e+02\n",
      "  -1.81000000e+01  3.45000000e+00  2.90000000e-01  4.97700000e+03\n",
      "  -3.10000000e-01 -6.00233000e+01 -2.64000000e+01  6.04200000e-01\n",
      "   9.17000000e-01 -1.50000000e-01 -1.40000000e-01  5.60000000e-01\n",
      "   4.00000000e-02  7.40000000e-01]\n",
      " [ 5.80000000e-01  2.81109800e+02  2.81109800e+02  1.04320000e+03\n",
      "  -2.26300000e+01  1.38000000e+00  0.00000000e+00  5.36100000e+03\n",
      "  -6.02714085e-02  4.75520000e+01 -3.29000000e+01  1.03934000e+01\n",
      "   1.31100000e+00 -2.33000000e+00 -1.80000000e-01  2.70000000e-01\n",
      "   0.00000000e+00  2.90000000e-01]\n",
      " [ 1.01000000e+00  6.56211800e-01  6.56211800e-01  2.29300000e+02\n",
      "  -1.69600000e+01  2.13000000e+00  0.00000000e+00  3.05000000e+03\n",
      "  -6.02714085e-02 -6.26794000e+01 -2.63000000e+01  1.54930000e+00\n",
      "   8.60000000e-02 -3.90000000e-01 -1.70000000e-01  6.40000000e-01\n",
      "   0.00000000e+00  8.50000000e-01]\n",
      " [ 1.01000000e+00  6.50471900e-01  6.50472000e-01  2.28800000e+02\n",
      "  -1.69500000e+01  2.13000000e+00  0.00000000e+00  3.48200000e+03\n",
      "  -1.00000000e-01  4.99151000e+01 -2.63000000e+01  1.18350000e+00\n",
      "   2.70000000e-01 -3.50000000e-01 -1.70000000e-01  6.50000000e-01\n",
      "   0.00000000e+00  8.50000000e-01]\n",
      " [ 8.70000000e-01  2.22180000e+00  2.86096700e+00  3.54500000e+02\n",
      "  -2.15600000e+01  8.36000000e+00  1.30000000e-01  5.14400000e+03\n",
      "   8.00000000e-02 -2.70331000e+01 -2.79000000e+01  1.14220000e+00\n",
      "   1.00800000e+00 -1.33000000e+00  3.13000000e+00  2.30000000e-01\n",
      "   0.00000000e+00  5.40000000e-01]\n",
      " [ 1.39000000e+00  5.30653100e-01  5.63206900e-01  2.24100000e+02\n",
      "  -1.72800000e+01  2.65000000e+00  3.00000000e-02  3.35000000e+03\n",
      "  -5.50000000e-01 -3.49897000e+01 -2.61000000e+01  1.19000000e+00\n",
      "   2.51000000e-01 -2.20000000e-01 -1.60000000e-01  7.80000000e-01\n",
      "   0.00000000e+00  7.70000000e-01]\n",
      " [ 2.39000000e+00  3.68687200e+02  3.68687200e+02  1.11640000e+03\n",
      "  -2.50500000e+01  3.66000000e+00  0.00000000e+00  5.80300000e+03\n",
      "  -6.02714085e-02  4.80826000e+01 -3.32000000e+01  1.01580000e+01\n",
      "   1.85100000e+00 -2.37000000e+00 -1.40000000e-01  2.90000000e-01\n",
      "   0.00000000e+00  2.60000000e-01]\n",
      " [ 1.39000000e+00  4.90154800e-01  4.90154900e-01  2.13200000e+02\n",
      "  -1.71300000e+01  2.66000000e+00  0.00000000e+00  3.78400000e+03\n",
      "  -6.02714085e-02  4.69967000e+01 -2.60000000e+01  8.69900000e-01\n",
      "   4.56000000e-01 -3.00000000e-02 -1.60000000e-01  8.30000000e-01\n",
      "   0.00000000e+00  7.30000000e-01]\n",
      " [ 2.47000000e+00  1.14692900e+00  1.14692900e+00  2.63700000e+02\n",
      "  -1.87900000e+01  3.72000000e+00  0.00000000e+00  4.65500000e+03\n",
      "   1.50000000e-01  2.61500000e+01 -2.69000000e+01  8.79300000e-01\n",
      "   8.36000000e-01 -7.60000000e-01 -1.40000000e-01  4.60000000e-01\n",
      "   6.50000000e-01  7.70000000e-01]\n",
      " [ 4.20000000e-01  1.06184200e+00  1.06184200e+00  2.58600000e+02\n",
      "  -2.12100000e+01  1.17300000e+01  0.00000000e+00  5.52700000e+03\n",
      "  -6.02714085e-02  4.63785000e+01 -2.68000000e+01  6.00200000e-01\n",
      "   1.37800000e+00 -6.00000000e-01  5.92000000e+00  1.40000000e-01\n",
      "   0.00000000e+00  4.90000000e-01]\n",
      " [ 5.11500000e+01  6.49575800e+01  1.01151500e+02  9.15100000e+02\n",
      "  -2.74700000e+01  2.09900000e+01  2.30000000e-01  4.74200000e+03\n",
      "  -3.50000000e-01  1.77928000e+01 -3.18000000e+01  8.07400000e+00\n",
      "   2.47810000e+01 -2.21000000e+00  1.50700000e+01  5.00000000e-02\n",
      "   0.00000000e+00  6.00000000e-02]\n",
      " [ 2.29000000e+00  9.64858600e+00  9.64858700e+00  4.49000000e+02\n",
      "  -2.10300000e+01  3.58000000e+00  0.00000000e+00  5.44800000e+03\n",
      "  -6.02714085e-02  4.88318000e+01 -2.92000000e+01  1.86200000e+00\n",
      "   1.39200000e+00 -1.84000000e+00 -1.40000000e-01  3.50000000e-01\n",
      "   0.00000000e+00  3.90000000e-01]\n",
      " [ 1.05000000e+00  1.08262500e+02  1.08262500e+02  8.21800000e+02\n",
      "  -2.26000000e+01  2.19000000e+00  0.00000000e+00  5.88900000e+03\n",
      "  -6.02714085e-02  4.72470000e+01 -3.18000000e+01  5.33980000e+00\n",
      "   2.12800000e+00 -2.29000000e+00 -1.70000000e-01  2.90000000e-01\n",
      "   0.00000000e+00  3.00000000e-01]\n",
      " [ 1.43000000e+00  1.00352400e+00  1.22026900e+00  2.81900000e+02\n",
      "  -1.81700000e+01  2.70000000e+00  1.00000000e-01  3.38200000e+03\n",
      "   9.00000000e-02  5.22580000e+00 -2.70000000e+01  1.72270000e+00\n",
      "   2.15000000e-01 -8.60000000e-01 -1.60000000e-01  5.30000000e-01\n",
      "   7.90000000e-01  8.60000000e-01]\n",
      " [ 1.23000000e+00  7.76563000e-01  1.20700100e+00  3.02300000e+02\n",
      "  -1.79500000e+01  2.44000000e+00  2.30000000e-01  3.15900000e+03\n",
      "  -2.70000000e-01 -6.94610000e+00 -2.70000000e+01  1.98560000e+00\n",
      "   7.70000000e-02 -8.40000000e-01 -1.60000000e-01  5.30000000e-01\n",
      "   9.70000000e-01  8.90000000e-01]\n",
      " [ 3.32000000e+00  1.20485000e+00  1.20485000e+00  2.66900000e+02\n",
      "  -1.91500000e+01  4.28000000e+00  0.00000000e+00  5.32100000e+03\n",
      "  -6.02714085e-02  4.45258000e+01 -2.69000000e+01  6.89800000e-01\n",
      "   1.28000000e+00 -7.40000000e-01 -1.20000000e-01  3.70000000e-01\n",
      "   2.30000000e-01  7.20000000e-01]\n",
      " [ 1.41000000e+00  3.88223000e-01  3.88223000e-01  2.01100000e+02\n",
      "  -1.68900000e+01  2.68000000e+00  0.00000000e+00  4.86900000e+03\n",
      "  -2.10000000e-01  4.53499000e+01 -2.57000000e+01  4.67600000e-01\n",
      "   8.57000000e-01  4.50000000e-01 -1.60000000e-01  6.60000000e-01\n",
      "   0.00000000e+00  6.70000000e-01]\n",
      " [ 1.79000000e+00  2.90058700e-01  4.34285100e-01  2.31400000e+02\n",
      "  -1.73700000e+01  3.11000000e+00  2.10000000e-01  3.55000000e+03\n",
      "  -8.60000000e-01 -4.50183000e+01 -2.58000000e+01  9.40900000e-01\n",
      "   2.32000000e-01  1.20000000e-01 -1.50000000e-01  6.30000000e-01\n",
      "   0.00000000e+00  6.70000000e-01]\n",
      " [ 1.30000000e+00  6.46679900e-01  6.99982100e-01  2.37800000e+02\n",
      "  -1.74200000e+01  2.55000000e+00  4.00000000e-02  4.40200000e+03\n",
      "  -3.70000000e-01  3.92801000e+01 -2.63000000e+01  7.68500000e-01\n",
      "   6.81000000e-01 -3.40000000e-01 -1.60000000e-01  7.30000000e-01\n",
      "   4.00000000e-02  8.40000000e-01]\n",
      " [ 2.53000000e+00  6.16430600e-01  6.80433300e-01  2.37300000e+02\n",
      "  -1.82500000e+01  3.76000000e+00  5.00000000e-02  3.32300000e+03\n",
      "  -6.02714085e-02 -5.64523000e+01 -2.63000000e+01  1.33450000e+00\n",
      "   2.10000000e-01 -4.10000000e-01 -1.30000000e-01  4.60000000e-01\n",
      "   1.70000000e-01  7.10000000e-01]\n",
      " [ 2.04000000e+00  6.58488600e-01  7.85473000e-01  2.51200000e+02\n",
      "  -1.81600000e+01  3.36000000e+00  9.00000000e-02  3.37100000e+03\n",
      "  -6.02714085e-02 -1.77734000e+01 -2.65000000e+01  1.39050000e+00\n",
      "   2.44000000e-01 -5.30000000e-01 -1.40000000e-01  5.40000000e-01\n",
      "   4.20000000e-01  7.70000000e-01]\n",
      " [ 6.10000000e-01  3.77289300e-01  3.77289300e-01  1.99700000e+02\n",
      "  -1.62000000e+01  1.98000000e+00  0.00000000e+00  2.55000000e+03\n",
      "   4.00000000e-02 -5.04140000e+00 -2.57000000e+01  1.68070000e+00\n",
      "   5.10000000e-02  1.40000000e-01  2.70000000e-01  5.90000000e-01\n",
      "   0.00000000e+00  6.80000000e-01]\n",
      " [ 1.93000000e+00  8.63640500e+01  8.63640700e+01  7.76700000e+02\n",
      "  -2.32100000e+01  3.26000000e+00  0.00000000e+00  5.91300000e+03\n",
      "  -6.02714085e-02  4.69983000e+01 -3.16000000e+01  4.73030000e+00\n",
      "   1.90400000e+00 -2.27000000e+00 -1.50000000e-01  3.00000000e-01\n",
      "   0.00000000e+00  2.80000000e-01]\n",
      " [ 6.90000000e-01  1.12972500e+00  1.12972500e+00  2.62700000e+02\n",
      "  -1.67400000e+01  1.47000000e+00  0.00000000e+00  2.55000000e+03\n",
      "   4.00000000e-02 -5.04140000e+00 -2.69000000e+01  2.90850000e+00\n",
      "   5.10000000e-02 -8.40000000e-01 -2.90000000e-01  4.50000000e-01\n",
      "   9.00000000e-01  9.00000000e-01]\n",
      " [ 5.10000000e-01  1.01827200e+01  1.01827200e+01  4.55100000e+02\n",
      "  -2.18400000e+01  5.07000000e+00  0.00000000e+00  5.69000000e+03\n",
      "  -6.02714085e-02  4.12953000e+01 -2.93000000e+01  1.75360000e+00\n",
      "   1.69300000e+00 -1.86000000e+00  2.44000000e+00  2.40000000e-01\n",
      "   0.00000000e+00  3.40000000e-01]\n",
      " [ 3.10000000e+00  4.26751600e-01  4.26751600e-01  2.05900000e+02\n",
      "  -1.79500000e+01  4.15000000e+00  0.00000000e+00  4.88000000e+03\n",
      "  -5.56000000e-01  4.38321000e+01 -2.58000000e+01  4.88000000e-01\n",
      "   8.46000000e-01  3.20000000e-01 -1.30000000e-01  3.60000000e-01\n",
      "   0.00000000e+00  6.10000000e-01]\n",
      " [ 2.07000000e+00  1.34437600e+00  1.34437600e+00  2.74300000e+02\n",
      "  -1.87600000e+01  3.38000000e+00  0.00000000e+00  4.09200000e+03\n",
      "  -6.02714085e-02  3.87435000e+01 -2.71000000e+01  1.23200000e+00\n",
      "   6.14000000e-01 -9.10000000e-01 -1.40000000e-01  4.90000000e-01\n",
      "   1.10000000e-01  7.80000000e-01]]\n",
      "['mesoplanet' 'mesoplanet' 'mesoplanet' 'non-habitable' 'psychroplanet'\n",
      " 'psychroplanet' 'psychroplanet' 'mesoplanet' 'mesoplanet' 'psychroplanet'\n",
      " 'non-habitable' 'non-habitable' 'non-habitable' 'mesoplanet'\n",
      " 'psychroplanet' 'non-habitable' 'psychroplanet' 'non-habitable'\n",
      " 'psychroplanet' 'psychroplanet' 'non-habitable' 'psychroplanet'\n",
      " 'non-habitable' 'psychroplanet' 'mesoplanet' 'non-habitable'\n",
      " 'non-habitable' 'non-habitable' 'non-habitable' 'mesoplanet' 'mesoplanet'\n",
      " 'mesoplanet' 'psychroplanet' 'psychroplanet' 'psychroplanet' 'mesoplanet'\n",
      " 'mesoplanet' 'psychroplanet' 'non-habitable' 'mesoplanet' 'non-habitable'\n",
      " 'psychroplanet' 'mesoplanet']\n",
      "[[ 1.61000000e+00  8.42771500e-01  8.76977600e-01  2.49000000e+02\n",
      "  -1.79700000e+01  2.92000000e+00  2.00000000e-02  3.35000000e+03\n",
      "  -5.50000000e-01 -3.49897000e+01 -2.66000000e+01  1.48480000e+00\n",
      "   2.51000000e-01 -6.20000000e-01 -1.50000000e-01  6.00000000e-01\n",
      "   6.40000000e-01  8.40000000e-01]\n",
      " [ 2.22000000e+00  4.47686800e-01  5.65604900e-01  2.35100000e+02\n",
      "  -1.79100000e+01  3.52000000e+00  1.20000000e-01  3.46600000e+03\n",
      "   2.00000000e-02 -2.51692000e+01 -2.61000000e+01  1.11790000e+00\n",
      "   3.09000000e-01 -2.10000000e-01 -1.40000000e-01  5.20000000e-01\n",
      "   0.00000000e+00  7.00000000e-01]\n",
      " [ 3.23000000e+00  2.34180500e-01  4.07107200e-01  2.38900000e+02\n",
      "  -1.70300000e+01  2.72000000e+00  2.90000000e-01  3.13100000e+03\n",
      "  -2.40000000e-01 -1.52714000e+01 -2.58000000e+01  1.18370000e+00\n",
      "   1.18000000e-01  1.80000000e-01 -8.20000000e-01  4.10000000e-01\n",
      "   0.00000000e+00  6.80000000e-01]\n",
      " [ 1.53000000e+00  1.12821300e+00  1.39841900e+00  2.93200000e+02\n",
      "  -1.84200000e+01  2.83000000e+00  1.10000000e-01  3.30500000e+03\n",
      "  -9.00000000e-02 -1.26626000e+01 -2.71000000e+01  1.93210000e+00\n",
      "   2.25000000e-01 -9.60000000e-01 -1.50000000e-01  5.10000000e-01\n",
      "   1.70000000e-01  8.20000000e-01]\n",
      " [ 3.06000000e+00  2.52642900e+01  2.52642900e+01  5.71200000e+02\n",
      "  -2.23900000e+01  4.13000000e+00  0.00000000e+00  5.10000000e+03\n",
      "  -2.80000000e-02  4.24363000e+01 -3.03000000e+01  3.43870000e+00\n",
      "   1.17000000e+00 -2.06000000e+00 -1.30000000e-01  3.20000000e-01\n",
      "   0.00000000e+00  3.00000000e-01]\n",
      " [ 2.37000000e+00  3.02060300e-01  3.67300600e-01  2.08800000e+02\n",
      "  -1.75100000e+01  3.64000000e+00  1.00000000e-01  3.02800000e+03\n",
      "  -6.02714085e-02 -4.36808000e+01 -2.56000000e+01  1.18310000e+00\n",
      "   2.32000000e-01  2.30000000e-01 -1.40000000e-01  4.50000000e-01\n",
      "   0.00000000e+00  5.90000000e-01]\n",
      " [ 5.68000000e+00  1.30501100e+02  1.68363400e+02  9.82300000e+02\n",
      "  -2.83100000e+01  2.42300000e+01  1.30000000e-01  5.97700000e+03\n",
      "   2.50000000e-01  4.29289000e+01 -3.23000000e+01  6.49360000e+00\n",
      "   2.56700000e+00 -2.33000000e+00  9.03000000e+00  9.00000000e-02\n",
      "   0.00000000e+00  8.00000000e-02]\n",
      " [ 2.86000000e+00  8.32599000e-01  8.32599200e-01  2.43400000e+02\n",
      "  -1.86000000e+01  4.00000000e+00  0.00000000e+00  3.72200000e+03\n",
      "  -6.02714085e-02  4.18121000e+01 -2.65000000e+01  1.17190000e+00\n",
      "   4.43000000e-01 -5.60000000e-01 -1.30000000e-01  4.10000000e-01\n",
      "   7.90000000e-01  7.40000000e-01]\n",
      " [ 4.15400000e+01  7.32789800e-03  4.46750400e-02  2.50100000e+02\n",
      "  -1.97200000e+01  2.13800000e+01  8.40000000e-01  4.95300000e+03\n",
      "   2.20000000e-01 -2.06619000e+01 -2.40000000e+01  2.08300000e-01\n",
      "   1.11500000e+00  1.03500000e+01  1.39000000e+01  3.00000000e-02\n",
      "   0.00000000e+00  1.00000000e-01]\n",
      " [ 4.30000000e+00  1.28953100e+00  1.28953100e+00  2.71500000e+02\n",
      "  -1.94500000e+01  4.75000000e+00  0.00000000e+00  4.46500000e+03\n",
      "  -1.21000000e-01  4.88254000e+01 -2.70000000e+01  1.01340000e+00\n",
      "   6.86000000e-01 -8.60000000e-01 -1.10000000e-01  3.00000000e-01\n",
      "   0.00000000e+00  6.80000000e-01]\n",
      " [ 6.20000000e-01  2.43748100e+01  2.43748100e+01  5.66100000e+02\n",
      "  -2.31700000e+01  6.03000000e+00  0.00000000e+00  5.20800000e+03\n",
      "   5.20000000e-02  4.48581000e+01 -3.02000000e+01  3.23890000e+00\n",
      "   1.19300000e+00 -2.06000000e+00  2.60000000e+00  2.30000000e-01\n",
      "   0.00000000e+00  2.50000000e-01]]\n",
      "['mesoplanet' 'psychroplanet' 'psychroplanet' 'mesoplanet' 'non-habitable'\n",
      " 'psychroplanet' 'non-habitable' 'mesoplanet' 'non-habitable' 'mesoplanet'\n",
      " 'non-habitable']\n"
     ]
    }
   ],
   "source": [
    "dataset_train = X_train.values\n",
    "X_train = dataset_train[:,1:19].astype(float)\n",
    "Y_train = dataset_train[:,0]\n",
    "dataset_test = X_test.values\n",
    "X_test = dataset_test[:,1:19].astype(float)\n",
    "Y_test = dataset_test[:,0] \n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_Y = encoder.transform(Y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y1 = np_utils.to_categorical(encoded_Y)\n",
    "#print(dummy_y1)\n",
    "\n",
    "encoder2 = LabelEncoder()\n",
    "encoder2.fit(Y_test)\n",
    "encoded_Y2 = encoder2.transform(Y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y2 = np_utils.to_categorical(encoded_Y2)\n",
    "print(dummy_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "#print(scaler.fit(X_train))\n",
    "#print(scaler.data_max_)\n",
    "#X_train = scaler.transform(X_train)\n",
    "\n",
    "X_train = stats.zscore(X_train, axis=1, ddof=1)\n",
    "\n",
    "#X_train = np.log(X_train + 1)\n",
    "#X_train = normalize(X_train)\n",
    "\n",
    "#transformer = Normalizer().fit(X_train)\n",
    "#X_train = transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    preds_correct_boolean =  np.argmax(predictions, 1) == np.argmax(labels, 1)\n",
    "    correct_predictions = np.sum(preds_correct_boolean)\n",
    "    accuracy = 100.0 * correct_predictions / predictions.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_activation(data_array):\n",
    "    return np.maximum(data_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(output_array):\n",
    "    logits_exp = np.exp(output_array.astype(np.float32))\n",
    "    return logits_exp / np.sum(logits_exp, axis = 1, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_softmax_loss_array(softmax_probs_array, y_onehot):\n",
    "    indices = np.argmax(y_onehot, axis = 1).astype(int)\n",
    "    predicted_probability = softmax_probs_array[np.arange(len(softmax_probs_array)), indices]\n",
    "    log_preds = np.log(predicted_probability)\n",
    "    loss = -1.0 * np.sum(log_preds) / len(log_preds)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization_L2_softmax_loss(reg_lambda, weight1, weight2):\n",
    "    weight1_loss = 0.5 * reg_lambda * np.sum(weight1 * weight1)\n",
    "    weight2_loss = 0.5 * reg_lambda * np.sum(weight2 * weight2)\n",
    "    return weight1_loss + weight2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step  0  :  2.0240180660930505\n",
      "Loss at step  100  :  1.6119641665321573\n",
      "Loss at step  200  :  1.5867972130284587\n",
      "Loss at step  300  :  1.5640076624589774\n",
      "Loss at step  400  :  1.5428644643051168\n",
      "Loss at step  500  :  1.5227114885046893\n",
      "Loss at step  600  :  1.5019646603842225\n",
      "Loss at step  700  :  1.4836111274982753\n",
      "Loss at step  800  :  1.4663074198524526\n",
      "Loss at step  900  :  1.448559126384389\n",
      "Loss at step  1000  :  1.4330010877537265\n",
      "Loss at step  1100  :  1.4183451311479534\n",
      "Loss at step  1200  :  1.4044977801036373\n",
      "Loss at step  1300  :  1.3913659883059766\n",
      "Loss at step  1400  :  1.3788640474375438\n",
      "Loss at step  1500  :  1.3669176960941154\n",
      "Loss at step  1600  :  1.3553221832955615\n",
      "Loss at step  1700  :  1.344203087299993\n",
      "Loss at step  1800  :  1.333547500304333\n",
      "Loss at step  1900  :  1.323259745617884\n",
      "Loss at step  2000  :  1.3133384384252031\n",
      "Loss at step  2100  :  1.3037507780778204\n",
      "Loss at step  2200  :  1.2944915209260515\n",
      "Loss at step  2300  :  1.285538048622122\n",
      "Loss at step  2400  :  1.2768591489431893\n",
      "Loss at step  2500  :  1.2684560417276884\n",
      "Loss at step  2600  :  1.2603115681937411\n",
      "Loss at step  2700  :  1.2523965974550237\n",
      "Loss at step  2800  :  1.2447302192160616\n",
      "Loss at step  2900  :  1.2372703030962329\n",
      "Loss at step  3000  :  1.2299500275537634\n",
      "Loss at step  3100  :  1.2229152024021326\n",
      "Loss at step  3200  :  1.2160108191904826\n",
      "Loss at step  3300  :  1.2093525403383554\n",
      "Loss at step  3400  :  1.20276171685112\n",
      "Loss at step  3500  :  1.1964012994055622\n",
      "Loss at step  3600  :  1.190192657434085\n",
      "Loss at step  3700  :  1.1841325376437302\n",
      "Loss at step  3800  :  1.1782248209761703\n",
      "Loss at step  3900  :  1.1724528963697756\n",
      "Loss at step  4000  :  1.1668083018389837\n",
      "Loss at step  4100  :  1.1612835833332322\n",
      "Loss at step  4200  :  1.15588052183867\n",
      "Loss at step  4300  :  1.1506155637042967\n",
      "Loss at step  4400  :  1.145468918499591\n",
      "Loss at step  4500  :  1.140431607622531\n",
      "Loss at step  4600  :  1.1355071994799355\n",
      "Loss at step  4700  :  1.1306881927518777\n",
      "Loss at step  4800  :  1.1259695273481287\n",
      "Loss at step  4900  :  1.1213564960478308\n",
      "Loss at step  5000  :  1.1168423500478994\n",
      "Loss at step  5100  :  1.1124238305543537\n",
      "Loss at step  5200  :  1.1080970292820536\n",
      "Loss at step  5300  :  1.1038655155512769\n",
      "Loss at step  5400  :  1.099720352496438\n",
      "Loss at step  5500  :  1.095663975280556\n"
     ]
    }
   ],
   "source": [
    "data = X_train\n",
    "labels = dummy_y1\n",
    "\n",
    "hidden_nodes = 6\n",
    "num_labels = labels.shape[1]\n",
    "num_features = data.shape[1]\n",
    "learning_rate = .01\n",
    "reg_lambda = .01\n",
    "\n",
    "# Weights and Bias Arrays\n",
    "layer1_weights_array = np.random.normal(0, 1, [num_features, hidden_nodes]) \n",
    "layer2_weights_array = np.random.normal(0, 1, [hidden_nodes, num_labels]) \n",
    "\n",
    "layer1_biases_array = np.zeros((1, hidden_nodes))\n",
    "layer2_biases_array = np.zeros((1, num_labels))\n",
    "\n",
    "\n",
    "for step in range(5501):\n",
    "\n",
    "    input_layer = np.dot(data, layer1_weights_array)\n",
    "    hidden_layer = relu_activation(input_layer + layer1_biases_array)\n",
    "    output_layer = np.dot(hidden_layer, layer2_weights_array) + layer2_biases_array\n",
    "    output_probs = softmax(output_layer)\n",
    "    \n",
    "    loss = cross_entropy_softmax_loss_array(output_probs, labels)\n",
    "    loss += regularization_L2_softmax_loss(reg_lambda, layer1_weights_array, layer2_weights_array)\n",
    "\n",
    "    output_error_signal = (output_probs - labels) / output_probs.shape[0]\n",
    "    \n",
    "    error_signal_hidden = np.dot(output_error_signal, layer2_weights_array.T) \n",
    "    error_signal_hidden[hidden_layer <= 0] = 0\n",
    "    \n",
    "    gradient_layer2_weights = np.dot(hidden_layer.T, output_error_signal)\n",
    "    gradient_layer2_bias = np.sum(output_error_signal, axis = 0, keepdims = True)\n",
    "    \n",
    "    gradient_layer1_weights = np.dot(data.T, error_signal_hidden)\n",
    "    gradient_layer1_bias = np.sum(error_signal_hidden, axis = 0, keepdims = True)\n",
    "\n",
    "    gradient_layer2_weights += reg_lambda * layer2_weights_array\n",
    "    gradient_layer1_weights += reg_lambda * layer1_weights_array\n",
    "\n",
    "    layer1_weights_array -= learning_rate * gradient_layer1_weights\n",
    "    layer1_biases_array -= learning_rate * gradient_layer1_bias\n",
    "    layer2_weights_array -= learning_rate * gradient_layer2_weights\n",
    "    layer2_biases_array -= learning_rate * gradient_layer2_bias\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "            print(\"Loss at step \" , step , \" : \" , loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.36363636363637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chirag/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/home/chirag/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "input_layer = np.dot(X_test, layer1_weights_array)\n",
    "hidden_layer = relu_activation(input_layer + layer1_biases_array)\n",
    "scores = np.dot(hidden_layer, layer2_weights_array) + layer2_biases_array\n",
    "probs = softmax(scores)\n",
    "print(accuracy(probs, dummy_y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]\n",
      " [ 0. nan  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
